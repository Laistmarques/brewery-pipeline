# Brewery Data Pipeline ðŸº

## ðŸ“Œ VisÃ£o Geral

Este projeto implementa uma pipeline de dados que segue a arquitetura
**Medallion (Bronze â†’ Silver â†’ Gold)** utilizando **Python, PySpark,
Apache Airflow e Docker**.

O objetivo Ã© consumir dados da API pÃºblica Open Brewery DB, processÃ¡-los
e gerar uma camada analÃ­tica agregada pronta para consultas.

------------------------------------------------------------------------

## ðŸ“¦ DependÃªncias do Projeto

### Requisitos

- **Python 3.10+** â€“ Linguagem principal do pipeline.
- **Docker** â€“ ContainerizaÃ§Ã£o do ambiente.
- **Docker Compose** â€“ OrquestraÃ§Ã£o dos serviÃ§os (Airflow, etc.).


### Principais Bibliotecas Python

**pyspark**  
Framework de processamento distribuÃ­do utilizado para:
- TransformaÃ§Ãµes nas camadas Silver e Gold
- AgregaÃ§Ãµes analÃ­ticas
- Escrita e leitura em formato Parquet
- Particionamento eficiente dos dados

**apache-airflow**  
Ferramenta de orquestraÃ§Ã£o utilizada para:
- Definir o fluxo Bronze â†’ Silver â†’ Gold
- Controlar dependÃªncias entre etapas
- Configurar retries automÃ¡ticos
- Monitorar execuÃ§Ãµes
- Agendar pipelines

**requests**  
Biblioteca HTTP utilizada na camada Bronze para:
- Consumir a API Open Brewery DB
- Implementar paginaÃ§Ã£o
- Controlar erros e retries

**pytest**  
Framework de testes utilizado para:
- Testes unitÃ¡rios de transformers
- Testes de jobs (mock de orquestraÃ§Ã£o)
- Testes de integraÃ§Ã£o de writers

**pytest-cov**  
ExtensÃ£o do pytest utilizada para:
- Medir cobertura de cÃ³digo
- Identificar partes do pipeline que nÃ£o estÃ£o sendo testadas
- Aumentar confiabilidade antes de deploy

### InstalaÃ§Ã£o (ExecuÃ§Ã£o Local)

``` bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

------------------------------------------------------------------------

## ðŸ— Arquitetura

```bash
                 +----------------------+
                 |  Open Brewery DB API |
                 +----------+-----------+
                            |
                            v
+----------------------+  extract   +-------------------------------+
| Airflow DAG (@daily) +----------->| Bronze (JSON raw)             |
| retries + timeout    |            | partition: ingestion_date     |
+----------+-----------+            +---------------+---------------+
           |                                           |
           |                               gate: check bronze exists
           v                                           v
+-------------------------------+          +-------------------------------+
| Silver (Parquet curated)      |<---------+ ShortCircuit / validation     |
| partition: date/country/state |          +-------------------------------+
+---------------+---------------+
                |
                v
+-------------------------------+
| Gold (Parquet analytics)      |
| count by type + location      |
| partition: date/country       |
+-------------------------------+
```

O pipeline Ã© dividido em trÃªs camadas:

### ðŸ¥‰ Bronze --- IngestÃ£o

-   Consome dados da API Open Brewery DB.
-   Implementa paginaÃ§Ã£o e controle de retry.
-   Armazena dados brutos em JSON.
-   Particionado por `ingestion_date`.

### ðŸ¥ˆ Silver --- PadronizaÃ§Ã£o

-   Seleciona colunas relevantes.
-   Renomeia `state_province` para `state`.
-   Remove registros com `country` ou `state` nulos.
-   Adiciona `ingestion_date`.
-   Armazena em Parquet.
-   Particionado por `ingestion_date`, `country` e `state`.

### ðŸ¥‡ Gold --- Camada AnalÃ­tica

-   Agrega por `brewery_type`, `country`, `state`, `city`.
-   MÃ©tricas:
    -   `num_breweries` (count distinct por id)
    -   `num_city`
-   Armazenado em Parquet.
-   Particionado por `ingestion_date` e `country`.

------------------------------------------------------------------------

## ðŸ“‚ Estrutura do Projeto

``` bash
brewery-pipeline/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ src/pipeline/
â”‚   â”‚   â”œâ”€â”€ bronze/
â”‚   â”‚   â”œâ”€â”€ silver/
â”‚   â”‚   â”œâ”€â”€ gold/
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â””â”€â”€ tests/
â”‚
â”œâ”€â”€ airflow/
â”‚   â””â”€â”€ dags/
â”‚       â””â”€â”€ brewery_pipeline_dag.py
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile.airflow
â””â”€â”€ README.md
```

------------------------------------------------------------------------

## ðŸ³ Executando com Docker e Airflow

``` bash
docker compose up --build
```

Acesse: http://localhost:8080

Credenciais padrÃ£o:
- UsuÃ¡rio: `airflow`
- Senha: `airflow`

Passos:
1. Despausar a DAG `brewery_pipeline_dag`
2. Executar manualmente ou aguardar o agendamento automÃ¡tico

------------------------------------------------------------------------
## ðŸ”„ Scheduling, Retries e Tratamento de Erros

A DAG foi configurada com:

- ExecuÃ§Ã£o diÃ¡ria
- 2 retries automÃ¡ticos em caso de falha
- Retry delay de 5 minutos
- Timeout por task
- SeparaÃ§Ã£o clara de etapas: Bronze â†’ Silver â†’ Gold
- Timeout de 30min 

Tratamento implementado:
- Controle de erros HTTP (429 / 5xx)
- PaginaÃ§Ã£o completa da API
- Logs estruturados
- Pipeline idempotente baseado em `ingestion_date`

------------------------------------------------------------------------

## ðŸ“‚ Estrutura FÃ­sica de SaÃ­da

### Bronze
```
data/bronze/ingestion_date=YYYY-MM-DD/*.json
```

### Silver
```
data/silver/ingestion_date=YYYY-MM-DD/country=XX/state=YY/*.parquet
```

### Gold
```
data/gold/ingestion_date=YYYY-MM-DD/country=XX/*.parquet
```

------------------------------------------------------------------------

## ðŸ–¥ ExecuÃ§Ã£o Local

``` bash
python -m src.pipeline.main --stage bronze --date 2026-02-11
python -m src.pipeline.main --stage silver --date 2026-02-11
python -m src.pipeline.main --stage gold --date 2026-02-11
```

------------------------------------------------------------------------

## ðŸ§ª Testes

``` bash
pytest --cov=src --cov-report=term-missing
```
Cobertura inclui:
- Testes unitÃ¡rios de transformers 
- Testes de jobs com mocks 
- Testes de integraÃ§Ã£o de writers 
- Mock da API


------------------------------------------------------------------------

## ðŸ“Š Monitoramento (atual) e melhorias para produÃ§Ã£o

### O que jÃ¡ existe hoje
- **OrquestraÃ§Ã£o via Airflow**: cada etapa (Bronze/Silver/Gold) Ã© executada como tarefa, com logs e status de execuÃ§Ã£o.
- **Retries / falhas**: o Airflow permite configurar tentativas automÃ¡ticas e facilita identificar rapidamente qual etapa falhou.
- **Logs estruturados**: logs do pipeline ajudam na investigaÃ§Ã£o (ex.: schema/colunas ausentes, paths e tempo de execuÃ§Ã£o).
- **Particionamento por `ingestion_date`**: facilita reprocessar somente o dia afetado sem reprocessar o dataset inteiro.

---

### O que eu faria para deixar â€œproduÃ§Ã£o-readyâ€

#### 1) Alertas e incident management

- **Alertas por falha de task** (Slack/Teams/PagerDuty): notificar automaticamente quando Bronze/Silver/Gold falhar.
- **Alertas por atraso (SLA)**: se a execuÃ§Ã£o do dia nÃ£o terminar atÃ© um horÃ¡rio limite, disparar alerta.
- **Escalonamento**: depois de X falhas consecutivas, abrir incidente.

#### 2) Observabilidade (mÃ©tricas e dashboards)

- Enviar mÃ©tricas para Prometheus/Grafana/Datadog/CloudWatch, por exemplo:
  - duraÃ§Ã£o por etapa (bronze/silver/gold)
  - nÃºmero de registros por camada
  - nÃºmero de partiÃ§Ãµes geradas por dia
  - volume de dados escrito (MB/GB)

- Criar dashboard com:
  - sucesso/falha por dia
  - tempo mÃ©dio por execuÃ§Ã£o
  - tendÃªncia de crescimento do dataset

#### 3) Data Quality automatizado (DQ)

AlÃ©m do pipeline â€œrodarâ€, garantir que os dados fazem sentido:
- **Checks de schema**: campos obrigatÃ³rios e tipos (ex.: `id` string, `country` string).
- **Checks de completude**: % nulos por coluna (ex.: `country/state` nÃ£o nulos na Silver).
- **Checks de unicidade**: `id` Ãºnico por dia/localidade (ou ao menos monitorar duplicidade).
- **Checks de consistÃªncia**: `brewery_count` >= 0, `city_count` <= `brewery_count`, etc.
- **Checks de freshness**: garantir que existe partiÃ§Ã£o `ingestion_date=YYYY-MM-DD` para o dia esperado.
- Ferramentas recomendadas: **Great Expectations** ou **Soda** (com relatÃ³rios por execuÃ§Ã£o).

#### 4) Ambiente e performance (Spark)
- Separar configuraÃ§Ãµes por ambiente (dev/staging/prod)
- Ajustar recursos no cluster (executors/memory/cores)
- PersistÃªncia de tabelas em storage confiÃ¡vel (S3/GCS/ADLS)


------------------------------------------------------------------------

## âš™ï¸ DecisÃµes TÃ©cnicas

-   PySpark para processamento escalÃ¡vel
-   Parquet para armazenamento eficiente
-   Particionamento por localizaÃ§Ã£o
-   Docker para ambiente reproduzÃ­vel
-   Airflow para orquestraÃ§Ã£o

------------------------------------------------------------------------

## ðŸš€ EvoluÃ§Ãµes Futuras

-   IntegraÃ§Ã£o com Delta Lake
-   Data Quality framework
-   CI/CD
-   Deploy em Cloud

------------------------------------------------------------------------

## ðŸ ConclusÃ£o

Projeto estruturado seguindo boas prÃ¡ticas de engenharia de dados, com
arquitetura clara, testes automatizados e ambiente reproduzÃ­vel.