# Brewery Data Pipeline ğŸº

## ğŸ“Œ VisÃ£o Geral

Este projeto implementa uma pipeline de dados que segue a arquitetura
**Medallion (Bronze â†’ Silver â†’ Gold)** utilizando **Python, PySpark,
Apache Airflow e Docker**.

O objetivo Ã© consumir dados da API pÃºblica Open Brewery DB, processÃ¡-los
e gerar uma camada analÃ­tica agregada pronta para consultas.

------------------------------------------------------------------------

## ğŸ“¦ DependÃªncias do Projeto

### Requisitos

- **Python 3.10+** â€“ Linguagem principal do pipeline.
- **Docker** â€“ ContainerizaÃ§Ã£o do ambiente.
- **Docker Compose** â€“ OrquestraÃ§Ã£o dos serviÃ§os (Airflow, etc.).


### Principais Bibliotecas Python

**pyspark**  
Framework de processamento distribuÃ­do utilizado para:
- TransformaÃ§Ãµes nas camadas Silver e Gold
- AgregaÃ§Ãµes analÃ­ticas
- Escrita e leitura em formato Parquet
- Particionamento eficiente dos dados

**apache-airflow**  
Ferramenta de orquestraÃ§Ã£o utilizada para:
- Definir o fluxo Bronze â†’ Silver â†’ Gold
- Controlar dependÃªncias entre etapas
- Configurar retries automÃ¡ticos
- Monitorar execuÃ§Ãµes
- Agendar pipelines

**requests**  
Biblioteca HTTP utilizada na camada Bronze para:
- Consumir a API Open Brewery DB
- Implementar paginaÃ§Ã£o
- Controlar erros e retries

**pytest**  
Framework de testes utilizado para:
- Testes unitÃ¡rios de transformers
- Testes de jobs (mock de orquestraÃ§Ã£o)
- Testes de integraÃ§Ã£o de writers

**pytest-cov**  
ExtensÃ£o do pytest utilizada para:
- Medir cobertura de cÃ³digo
- Identificar partes do pipeline que nÃ£o estÃ£o sendo testadas
- Aumentar confiabilidade antes de deploy

### InstalaÃ§Ã£o (ExecuÃ§Ã£o Local)

``` bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

------------------------------------------------------------------------

## ğŸ— Arquitetura

O pipeline Ã© dividido em trÃªs camadas:

### ğŸ¥‰ Bronze --- IngestÃ£o

-   Consome dados da API Open Brewery DB.
-   Implementa paginaÃ§Ã£o e controle de retry.
-   Armazena dados brutos em JSON.
-   Particionado por `ingestion_date`.

### ğŸ¥ˆ Silver --- PadronizaÃ§Ã£o

-   Seleciona colunas relevantes.
-   Renomeia `state_province` para `state`.
-   Remove registros com `country` ou `state` nulos.
-   Adiciona `ingestion_date`.
-   Armazena em Parquet.
-   Particionado por `ingestion_date`, `country` e `state`.

### ğŸ¥‡ Gold --- Camada AnalÃ­tica

-   Agrega por `brewery_type`, `country`, `state`, `city`.
-   MÃ©tricas:
    -   `num_breweries` (count distinct por id)
    -   `num_city`
-   Armazenado em Parquet.
-   Particionado por `ingestion_date` e `country`.

------------------------------------------------------------------------

## ğŸ“‚ Estrutura do Projeto

``` bash
brewery-pipeline/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ src/pipeline/
â”‚   â”‚   â”œâ”€â”€ bronze/
â”‚   â”‚   â”œâ”€â”€ silver/
â”‚   â”‚   â”œâ”€â”€ gold/
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â””â”€â”€ tests/
â”‚
â”œâ”€â”€ airflow/
â”‚   â””â”€â”€ dags/
â”‚       â””â”€â”€ brewery_pipeline_dag.py
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile.airflow
â””â”€â”€ README.md
```

------------------------------------------------------------------------

## ğŸ³ Executando com Docker e Airflow

``` bash
docker compose up --build
```

Acesse: http://localhost:8080

Ative e execute o DAG `brewery_pipeline_dag`.

------------------------------------------------------------------------

## ğŸ–¥ ExecuÃ§Ã£o Local

``` bash
python -m src.pipeline.main --stage bronze --date 2026-02-11
python -m src.pipeline.main --stage silver --date 2026-02-11
python -m src.pipeline.main --stage gold --date 2026-02-11
```

------------------------------------------------------------------------

## ğŸ§ª Testes

``` bash
pytest --cov=src --cov-report=term-missing
```
Inclui: 
- Testes unitÃ¡rios de transformers 
- Testes de jobs com mocks 
- Testes de integraÃ§Ã£o de writers 
- Mock da API


------------------------------------------------------------------------

## ğŸ“Š Monitoramento (atual) e melhorias para produÃ§Ã£o

### O que jÃ¡ existe hoje
- **OrquestraÃ§Ã£o via Airflow**: cada etapa (Bronze/Silver/Gold) Ã© executada como tarefa, com logs e status de execuÃ§Ã£o.
- **Retries / falhas**: o Airflow permite configurar tentativas automÃ¡ticas e facilita identificar rapidamente qual etapa falhou.
- **Logs estruturados**: logs do pipeline ajudam na investigaÃ§Ã£o (ex.: schema/colunas ausentes, paths e tempo de execuÃ§Ã£o).
- **Particionamento por `ingestion_date`**: facilita reprocessar somente o dia afetado sem reprocessar o dataset inteiro.

---

### O que eu faria para deixar â€œproduÃ§Ã£o-readyâ€

#### 1) Alertas e incident management

- **Alertas por falha de task** (Slack/Teams/PagerDuty): notificar automaticamente quando Bronze/Silver/Gold falhar.
- **Alertas por atraso (SLA)**: se a execuÃ§Ã£o do dia nÃ£o terminar atÃ© um horÃ¡rio limite, disparar alerta.
- **Escalonamento**: depois de X falhas consecutivas, abrir incidente.

#### 2) Observabilidade (mÃ©tricas e dashboards)

- Enviar mÃ©tricas para Prometheus/Grafana/Datadog/CloudWatch, por exemplo:
  - duraÃ§Ã£o por etapa (bronze/silver/gold)
  - nÃºmero de registros por camada
  - nÃºmero de partiÃ§Ãµes geradas por dia
  - volume de dados escrito (MB/GB)

- Criar dashboard com:
  - sucesso/falha por dia
  - tempo mÃ©dio por execuÃ§Ã£o
  - tendÃªncia de crescimento do dataset

#### 3) Data Quality automatizado (DQ)

AlÃ©m do pipeline â€œrodarâ€, garantir que os dados fazem sentido:
- **Checks de schema**: campos obrigatÃ³rios e tipos (ex.: `id` string, `country` string).
- **Checks de completude**: % nulos por coluna (ex.: `country/state` nÃ£o nulos na Silver).
- **Checks de unicidade**: `id` Ãºnico por dia/localidade (ou ao menos monitorar duplicidade).
- **Checks de consistÃªncia**: `brewery_count` >= 0, `city_count` <= `brewery_count`, etc.
- **Checks de freshness**: garantir que existe partiÃ§Ã£o `ingestion_date=YYYY-MM-DD` para o dia esperado.
- Ferramentas recomendadas: **Great Expectations** ou **Soda** (com relatÃ³rios por execuÃ§Ã£o).

#### 4) Ambiente e performance (Spark)
- Separar configuraÃ§Ãµes por ambiente (dev/staging/prod)
- Ajustar recursos no cluster (executors/memory/cores)
- PersistÃªncia de tabelas em storage confiÃ¡vel (S3/GCS/ADLS)


------------------------------------------------------------------------

## âš™ï¸ DecisÃµes TÃ©cnicas

-   PySpark para processamento escalÃ¡vel
-   Parquet para armazenamento eficiente
-   Particionamento por localizaÃ§Ã£o
-   Docker para ambiente reproduzÃ­vel
-   Airflow para orquestraÃ§Ã£o

------------------------------------------------------------------------

## ğŸš€ EvoluÃ§Ãµes Futuras

-   IntegraÃ§Ã£o com Delta Lake
-   Data Quality framework
-   CI/CD
-   Deploy em Cloud

------------------------------------------------------------------------

## ğŸ ConclusÃ£o

Projeto estruturado seguindo boas prÃ¡ticas de engenharia de dados, com
arquitetura clara, testes automatizados e ambiente reproduzÃ­vel.