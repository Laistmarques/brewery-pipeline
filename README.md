# Brewery Data Pipeline ðŸº

## ðŸ“Œ Contexto do Desafio

O desafio consistiu em construir uma pipeline de dados a partir da API pÃºblica Open Brewery DB, garantindo:

- OrganizaÃ§Ã£o em camadas

- Reprocessamento por data

- SeparaÃ§Ã£o clara de responsabilidades

- Estrutura preparada para evoluÃ§Ã£o futura

A soluÃ§Ã£o foi implementada utilizando Python, PySpark, Apache Airflow e Docker, seguindo o padrÃ£o Medallion Architecture (Bronze â†’ Silver â†’ Gold).

## ðŸ“Œ VisÃ£o Geral

A pipeline realiza:

- ExtraÃ§Ã£o paginada da API

- Armazenamento bruto (Bronze)

- PadronizaÃ§Ã£o e limpeza (Silver)

- AgregaÃ§Ã£o analÃ­tica (Gold)

O resultado final Ã© uma camada analÃ­tica pronta para consumo.

------------------------------------------------------------------------

## ðŸ“¦ DependÃªncias do Projeto

### Requisitos

- **Python 3.10+** â€“ Linguagem principal do pipeline.
- **Docker** â€“ ContainerizaÃ§Ã£o do ambiente.
- **Docker Compose** â€“ OrquestraÃ§Ã£o dos serviÃ§os (Airflow, etc.).


### Principais Bibliotecas Python

**pyspark**  
Framework de processamento distribuÃ­do utilizado para:
- TransformaÃ§Ãµes nas camadas Silver e Gold
- AgregaÃ§Ãµes analÃ­ticas
- Escrita e leitura em formato Parquet
- Particionamento eficiente dos dados

**apache-airflow**  
Ferramenta de orquestraÃ§Ã£o utilizada para:
- Definir o fluxo Bronze â†’ Silver â†’ Gold
- Controlar dependÃªncias entre etapas
- Configurar retries automÃ¡ticos
- Monitorar execuÃ§Ãµes
- Agendar pipelines

**requests**  
Biblioteca HTTP utilizada na camada Bronze para:
- Consumir a API Open Brewery DB
- Implementar paginaÃ§Ã£o
- Controlar erros e retries

**pytest**  
Framework de testes utilizado para:
- Testes unitÃ¡rios de transformers
- Testes de jobs (mock de orquestraÃ§Ã£o)
- Testes de integraÃ§Ã£o de writers

**pytest-cov**  
ExtensÃ£o do pytest utilizada para:
- Medir cobertura de cÃ³digo
- Identificar partes do pipeline que nÃ£o estÃ£o sendo testadas
- Aumentar confiabilidade antes de deploy

### InstalaÃ§Ã£o (ExecuÃ§Ã£o Local)

``` bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

------------------------------------------------------------------------

## ðŸ— Arquitetura

```bash
                 +----------------------+
                 |  Open Brewery DB API |
                 +----------+-----------+
                            |
                            v
+----------------------+  extract   +-------------------------------+
| Airflow DAG (@daily) +----------->| Bronze (JSON raw)             |
| retries + timeout    |            | partition: ingestion_date     |
+----------+-----------+            +---------------+---------------+
           |                                           |
           |                               gate: check bronze exists
           v                                           v
+-------------------------------+          +-------------------------------+
| Silver (Parquet curated)      |<---------+ ShortCircuit / validation     |
| partition: date/country/state |          +-------------------------------+
+---------------+---------------+
                |
                v
+-------------------------------+
| Gold (Parquet analytics)      |
| count by type + location      |
| partition: date/country       |
+-------------------------------+
```

A arquitetura foi projetada para garantir:

- SeparaÃ§Ã£o clara entre ingestÃ£o, transformaÃ§Ã£o e agregaÃ§Ã£o

- IdempotÃªncia por data

- Reprocessamento seguro

- EvoluÃ§Ã£o futura para Data Lake ou storage cloud

O pipeline Ã© dividido em trÃªs camadas:

### ðŸ¥‰ Bronze --- IngestÃ£o

-   Consome dados da API Open Brewery DB.
-   Implementa paginaÃ§Ã£o e controle de retry.
-   Armazena dados brutos em JSON.
-   Particionado por `ingestion_date`.

### ðŸ¥ˆ Silver --- PadronizaÃ§Ã£o

-   Seleciona colunas relevantes.
-   Renomeia `state_province` para `state`.
-   Remove registros com `country` ou `state` nulos.
-   Adiciona `ingestion_date`.
-   Armazena em Parquet.
-   Particionado por `ingestion_date`, `country` e `state`.

### ðŸ¥‡ Gold --- Camada AnalÃ­tica

-   Agrega por `brewery_type`, `country`, `state`, `city`.
-   MÃ©tricas:
    -   `num_breweries` (count distinct por id)
    -   `num_city`
-   Armazenado em Parquet.
-   Particionado por `ingestion_date` e `country`.

## âš–ï¸ DecisÃµes TÃ©cnicas e Arquiteturais

Nesta seÃ§Ã£o explico as principais decisÃµes tÃ©cnicas adotadas no projeto.

---

### ðŸ—‚ï¸ Uso do Parquet

Optei por utilizar **Parquet** nas camadas Silver e Gold por ser um formato colunar, eficiente para consultas analÃ­ticas e totalmente integrado ao Spark.

MantÃ©m simplicidade e performance adequadas ao escopo do case.

---

ðŸ§± EstratÃ©gia de Particionamento

A Silver Ã© particionada por:

- ingestion_date

- country

- state

A Gold Ã© particionada por:

- ingestion_date

- country

Essa estratÃ©gia:

- Permite partition pruning

- Facilita reprocessamento por data

- MantÃ©m organizaÃ§Ã£o lÃ³gica dos dados

- Evita sobrescrita completa do dataset

---

### ðŸ” Overwrite por partiÃ§Ã£o (e nÃ£o total)

Implementei sobrescrita dinÃ¢mica de partiÃ§Ã£o para permitir reprocessamento de datas especÃ­ficas sem apagar histÃ³rico.

Isso garante:
- IdempotÃªncia
- SeguranÃ§a no reprocessamento
- PreservaÃ§Ã£o das demais partiÃ§Ãµes

---

### âš™ï¸ OrquestraÃ§Ã£o com Airflow (LocalExecutor)

O Airflow foi utilizado para:

- Definir dependÃªncias Bronze â†’ Silver â†’ Gold

- Configurar retries automÃ¡ticos

- Controlar timeout por task

- Monitorar execuÃ§Ãµes

O LocalExecutor foi escolhido por ser suficiente para o escopo do projeto, mantendo simplicidade e paralelismo bÃ¡sico.

---

### ðŸ³ Spark containerizado

Executar Spark dentro do Docker garante:
- Reprodutibilidade
- Ambiente consistente
- Facilidade para avaliaÃ§Ã£o do projeto

------------------------------------------------------------------------

## ðŸ“‚ Estrutura do Projeto

``` bash
brewery-pipeline/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pipeline/
â”‚   â”‚   â”œâ”€â”€ bronze/
â”‚   â”‚   â”œâ”€â”€ silver/
â”‚   â”‚   â”œâ”€â”€ gold/
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â””â”€â”€ tests/
â”‚
â”œâ”€â”€ airflow/
â”‚   â””â”€â”€ dags/
â”‚       â””â”€â”€ brewery_pipeline_dag.py
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile.airflow
â””â”€â”€ README.md
```

------------------------------------------------------------------------

## ðŸ³ Executando com Docker e Airflow

``` bash
docker compose up --build
```

Acesse: http://localhost:8080

Credenciais padrÃ£o:
- UsuÃ¡rio: `admin`
- Senha: `admin`

Passos:
1. Despausar a DAG `brewery_pipeline_dag`
2. Executar manualmente ou aguardar o agendamento automÃ¡tico

------------------------------------------------------------------------
## ðŸ”„ Scheduling, Retries e Tratamento de Erros

A DAG foi configurada com:

- ExecuÃ§Ã£o diÃ¡ria
- 2 retries automÃ¡ticos em caso de falha
- Retry delay de 5 minutos
- Timeout de 30 min por task
- SeparaÃ§Ã£o clara de etapas: Bronze â†’ Silver â†’ Gold

Tratamento implementado:
- Controle de erros HTTP (429 / 5xx)
- PaginaÃ§Ã£o completa da API
- Logs estruturados
- Pipeline idempotente baseado em `ingestion_date`

------------------------------------------------------------------------

## ðŸ“‚ Estrutura FÃ­sica de SaÃ­da

### Bronze
```
data/bronze/ingestion_date=YYYY-MM-DD/*.json
```

### Silver
```
data/silver/ingestion_date=YYYY-MM-DD/country=XX/state=YY/*.parquet
```

### Gold
```
data/gold/ingestion_date=YYYY-MM-DD/country=XX/*.parquet
```

------------------------------------------------------------------------

## ðŸ–¥ ExecuÃ§Ã£o Local

``` bash
python -m pipeline.main --stage bronze --date 2026-02-11
python -m pipeline.main --stage silver --date 2026-02-11
python -m pipeline.main --stage gold --date 2026-02-11
```

------------------------------------------------------------------------

## ðŸ§ª Testes

``` bash
pytest --cov=pipeline --cov-report=term-missing
```
Cobertura inclui:
- Testes unitÃ¡rios de transformers 
- Testes de jobs com mocks 
- Testes de integraÃ§Ã£o de writers 
- Mock da API


------------------------------------------------------------------------

## ðŸ“Š Monitoramento (atual) e melhorias para produÃ§Ã£o

### O que jÃ¡ existe hoje
- **OrquestraÃ§Ã£o via Airflow**: cada etapa (Bronze/Silver/Gold) Ã© executada como tarefa, com logs e status de execuÃ§Ã£o.
- **Retries / falhas**: o Airflow permite configurar tentativas automÃ¡ticas e facilita identificar rapidamente qual etapa falhou.
- **Logs estruturados**: logs do pipeline ajudam na investigaÃ§Ã£o (ex.: schema/colunas ausentes, paths e tempo de execuÃ§Ã£o).
- **Particionamento por `ingestion_date`**: facilita reprocessar somente o dia afetado sem reprocessar o dataset inteiro.

---

### O que eu faria para deixar â€œproduÃ§Ã£o-readyâ€

#### 1) Alertas e incident management

- **Alertas por falha de task** (Slack/Teams/PagerDuty): notificar automaticamente quando Bronze/Silver/Gold falhar.
- **Alertas por atraso (SLA)**: se a execuÃ§Ã£o do dia nÃ£o terminar atÃ© um horÃ¡rio limite, disparar alerta.
- **Escalonamento**: depois de X falhas consecutivas, abrir incidente.

#### 2) Observabilidade (mÃ©tricas e dashboards)

- Enviar mÃ©tricas para Prometheus/Grafana/Datadog/CloudWatch, por exemplo:
  - duraÃ§Ã£o por etapa (bronze/silver/gold)
  - nÃºmero de registros por camada
  - nÃºmero de partiÃ§Ãµes geradas por dia
  - volume de dados escrito (MB/GB)

- Criar dashboard com:
  - sucesso/falha por dia
  - tempo mÃ©dio por execuÃ§Ã£o
  - tendÃªncia de crescimento do dataset

#### 3) Data Quality automatizado (DQ)

AlÃ©m do pipeline â€œrodarâ€, garantir que os dados fazem sentido:
- **Checks de schema**: campos obrigatÃ³rios e tipos (ex.: `id` string, `country` string).
- **Checks de completude**: % nulos por coluna (ex.: `country/state` nÃ£o nulos na Silver).
- **Checks de unicidade**: `id` Ãºnico por dia/localidade (ou ao menos monitorar duplicidade).
- **Checks de consistÃªncia**: `brewery_count` >= 0, `city_count` <= `brewery_count`, etc.
- **Checks de freshness**: garantir que existe partiÃ§Ã£o `ingestion_date=YYYY-MM-DD` para o dia esperado.
- Ferramentas recomendadas: **Great Expectations** ou **Soda** (com relatÃ³rios por execuÃ§Ã£o).

#### 4) Ambiente e performance (Spark)
- Separar configuraÃ§Ãµes por ambiente (dev/staging/prod)
- Ajustar recursos no cluster (executors/memory/cores)
- PersistÃªncia de tabelas em storage confiÃ¡vel (S3/GCS/ADLS)


------------------------------------------------------------------------

## âš™ï¸ DecisÃµes TÃ©cnicas

-   PySpark para processamento escalÃ¡vel
-   Parquet para armazenamento eficiente
-   Particionamento por localizaÃ§Ã£o
-   Docker para ambiente reproduzÃ­vel
-   Airflow para orquestraÃ§Ã£o

------------------------------------------------------------------------

## ðŸš€ EvoluÃ§Ãµes Futuras

1. Data Quality automatizado
2. Armazenamento transacional (Delta Lake)
3. Deploy em ambiente cloud
4. CI/CD


------------------------------------------------------------------------

## ðŸ ConclusÃ£o

A soluÃ§Ã£o foi construÃ­da priorizando:

- Clareza arquitetural

- IdempotÃªncia

- Reprocessamento seguro

- OrganizaÃ§Ã£o analÃ­tica

- Ambiente reproduzÃ­vel

MantÃ©m simplicidade adequada ao escopo do case, mas jÃ¡ estruturada para evoluÃ§Ãµes futuras em ambiente produtivo.